{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Prepare the environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Overall documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-speech-create-project?pivots=rest-api)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import standard python libraries\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697550084569
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#os.chdir(\"../Airlift/Speech/Train a Custom Model\")\n",
        "if not load_dotenv('./mydotenv.env'): raise Exception(\".env file not found\")"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697552037865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the credentials\n",
        "speech_key = os.getenv(\"SPEECH_KEY\")\n",
        "\n",
        "# Set the API key and endpoint\n",
        "endpoint = os.getenv(\"SPEECH_ENDPOINT\")\n",
        "region = os.getenv(\"SPEECH_REGION\")\n",
        "\n",
        "# Define the locale for the custom model\n",
        "locale = \"en-US\""
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697552040691
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Prepare the Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1. Get an opensource dataset\n",
        "\n",
        " - Audios collected from [here](http://www.voiptroubleshooter.com/open_speech/american.html)\n",
        " - Transcriptions collected from [here](http://www.cs.columbia.edu/~hgs/audio/harvard.html)\n",
        "\n",
        " Other sources of dataset download, from [Mozilla Common Voice project](https://commonvoice.mozilla.org/en/languages) under CC-0 license."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the audio properties meet the requirements\n",
        "```\n",
        "cd Airlift/Speech/\"Train a Custom Model\"\n",
        "find . -type f -name \"*.wav\" -print0 | xargs -0 -I {} sh -c 'ffprobe \"{}\" 2>&1 | grep -A1 Duration:'\n",
        "```\n",
        "\n",
        "Requirements:\n",
        "![File properties](img/custom_speech_audio_format.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Load the labeled transcriptions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty dict \n",
        "content_list = []\n",
        "\n",
        "# Specify the folder path where the .txt files are located\n",
        "folder_path = './dataset/transcriptions'\n",
        "\n",
        "# List all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Filter .txt files\n",
        "txt_files = [file for file in files if file.endswith('.txt')]\n",
        "\n",
        "# Loop through each .txt file and perform operations\n",
        "for txt_file in txt_files:\n",
        "    # Create the complete file path by joining folder path and file name\n",
        "    file_path = os.path.join(folder_path, txt_file)\n",
        "    \n",
        "    # Open and read the file\n",
        "    with open(file_path, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        content_list.append({\"path\": txt_file.replace(\".txt\", \".wav\"), \"sentence\": file_content.replace(\"\\n\", \" \").replace('\"', '')})\n",
        "\n",
        "# Generate a dataframe with the labeled examples\n",
        "df = pd.DataFrame(content_list)\n",
        "\n",
        "# Save to disc\n",
        "df.to_csv(\"./dataset/audio_files/labels.tsv\", sep = \"\\t\", index = False)\n",
        "\n",
        "# Show first examples\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "                     path                                           sentence\n0  OSR_us_000_0010_8k.wav  The birch canoe slid on the smooth planks. Glu...\n1  OSR_us_000_0011_8k.wav  The boy was there when the sun rose. A rod is ...\n2  OSR_us_000_0012_8k.wav  The small pup gnawed a hole in the sock. The f...\n3  OSR_us_000_0013_8k.wav  Hoist the load to your left shoulder. Take the...\n4  OSR_us_000_0014_8k.wav  A king ruled the state in the early days. The ...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OSR_us_000_0010_8k.wav</td>\n      <td>The birch canoe slid on the smooth planks. Glu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OSR_us_000_0011_8k.wav</td>\n      <td>The boy was there when the sun rose. A rod is ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OSR_us_000_0012_8k.wav</td>\n      <td>The small pup gnawed a hole in the sock. The f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OSR_us_000_0013_8k.wav</td>\n      <td>Hoist the load to your left shoulder. Take the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OSR_us_000_0014_8k.wav</td>\n      <td>A king ruled the state in the early days. The ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697553473536
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the audio files + labels\n",
        "```\n",
        "cd dataset/audio_files/\n",
        "zip training_data.zip ./*.*\n",
        "```\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create the Project\n",
        "\n",
        "[Documentation for the API](#https://eastus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-1/operations/Projects_Create)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the headers for the REST API calls\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Define the request body for a new custom speech project\n",
        "create_project_request_body = {\n",
        "  \"displayName\": \"demo_airlift\",\n",
        "  \"description\": \"Custom Model Training using APIs\",\n",
        "  \"locale\": locale\n",
        "}\n",
        "\n",
        "# Build and call the URI\n",
        "create_project_uri = f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/projects\"\n",
        "create_project_response = requests.post(url = create_project_uri, headers = headers, json = create_project_request_body)\n",
        "\n",
        "# 20* Represents a successful call \n",
        "print(\"HTTP Status code:\", create_project_response.status_code)\n",
        "\n",
        "# Get the project ID\n",
        "project_id = json.loads(create_project_response.text)[\"links\"][\"datasets\"].split(\"/\")[-2]\n",
        "print(\"Project ID #:\", project_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HTTP Status code: 201\nProject ID #: c1db0548-2b25-4f9e-8bed-e826bb7382e1\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697552956518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create the dataset\n",
        "\n",
        "[Documentation for the API](https://eastus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-1/operations/Datasets_Create)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pointer to the blob location containig the file\n",
        "training_data_location = \"https://customspeechdemo.blob.core.windows.net/dataset/training_data.zip?sp=r&st=2023-10-17T14:41:35Z&se=2023-12-31T23:41:35Z&spr=https&sv=2022-11-02&sr=b&sig=rEBDPZB0fIsHNduwPMPk41CTM6UcxsBd7e10nlfiZMo%3D\"\n",
        "\n",
        "# Define the headers for the REST API calls\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Define the request body for a new dataset\n",
        "create_dataset_request_body = {\n",
        "  \"kind\": \"Acoustic\",\n",
        "  \"displayName\": \"training_data\",\n",
        "  \"description\": \"Training Data, added via API call\",\n",
        "  \"project\": {\n",
        "    \"self\": f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/projects/{project_id}\"\n",
        "  },\n",
        "  \"contentUrl\": training_data_location,\n",
        "  \"locale\": locale\n",
        "}\n",
        "\n",
        "# Build and call the URI\n",
        "create_dataset_uri = f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/datasets\"\n",
        "create_dataset_response = requests.post(url = create_dataset_uri, headers = headers, json = create_dataset_request_body)\n",
        "\n",
        "# 20* Represents a successful call \n",
        "print(\"HTTP Status code:\", create_dataset_response.status_code)\n",
        "\n",
        "# Get the dataset ID\n",
        "dataset_id = json.loads(create_dataset_response.text)[\"links\"][\"files\"].split(\"/\")[-2]\n",
        "print(\"Dataset ID #:\", dataset_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HTTP Status code: 201\nDataset ID #: 4ea90e2c-b3af-445b-ba08-95f4d50d3d58\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697553739600
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Get the base models for Acoustic training\n",
        "\n",
        "[Documentation for the API](https://eastus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-1/operations/Models_GetBaseModel)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the headers for the REST API calls\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Define the request body for getting the base models\n",
        "get_base_model_request_body = {\n",
        "  \"locale\": locale\n",
        "}\n",
        "\n",
        "# Build and call the URI\n",
        "get_base_model_uri = f\"https://{region}.cognitiveservices.azure.com/speechtotext/v3.1/models/base/?skip=900&top=100\"\n",
        "get_model_response = requests.get(url = get_base_model_uri, headers = headers, json = get_base_model_request_body)\n",
        "\n",
        "# 20* Represents a successful call \n",
        "print(\"HTTP Status code:\", get_model_response.status_code)\n",
        "\n",
        "# Get and print base model details\n",
        "base_models = json.loads(get_model_response.text)[\"values\"]\n",
        "for model in base_models:\n",
        "    if model[\"locale\"] == locale and \"Acoustic\" in base_models[0][\"properties\"][\"features\"][\"supportsAdaptationsWith\"]:\n",
        "        base_model_url = model[\"self\"]\n",
        "        base_model_display_name = model[\"displayName\"]\n",
        "        print(\"Acoustic model for base model:\", base_model_display_name, \"\\n\", base_model_url, \"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HTTP Status code: 200\nAcoustic model for base model: 20230315 Batch Transcription \n https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/ea09791c-0745-41dd-a79c-e6f154678de4 \n\n\nAcoustic model for base model: 20230301 Batch Transcription \n https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/eb66f70e-c649-40d8-b205-e017c87a96fe \n\n\nAcoustic model for base model: 20230915 Whisper Preview \n https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/8cd2b1e5-985c-4c77-bfb0-e6ab1798826b \n\n\nAcoustic model for base model: 20230724 \n https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/e829074a-0c34-40d9-81af-e6cae17a4266 \n\n\nAcoustic model for base model: 20231005 Batch Transcription \n https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/65d19d52-4766-429a-870c-b263b3aebab7 \n\n\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697551789839
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base model\n",
        "base_model_url = \"https://westeurope.cognitiveservices.azure.com/speechtotext/v3.1/models/base/801f5620-13c1-4883-9e39-9275bf97576d\""
      ],
      "outputs": [],
      "execution_count": 68,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697554164948
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model Training\n",
        "\n",
        "[Documentation for the API](https://eastus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-1/operations/Models_Create)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the headers for the REST API calls\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Define the request body for a new dataset\n",
        "train_model_request_body = {\n",
        "  \"project\": {\n",
        "    \"self\": f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/projects/{project_id}\"\n",
        "  },\n",
        "  \"datasets\": [\n",
        "    {\n",
        "      \"self\": f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/{dataset_id}\"\n",
        "    }\n",
        "  ],\n",
        "  \"locale\": locale,\n",
        "  \"displayName\": \"custom_model_airlift_demo\",\n",
        "  \"description\": \"Custom Model for the Airlift Demo\",\n",
        "  \"baseModel\": {\n",
        "    \"self\": base_model_url\n",
        "  }\n",
        "}\n",
        "\n",
        "# Build and call the URI\n",
        "train_model_uri = f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/models\"\n",
        "train_model_response = requests.post(url = train_model_uri, headers = headers, json = train_model_request_body)\n",
        "\n",
        "# 20* Represents a successful call \n",
        "print(train_model_response.status_code)\n",
        "\n",
        "# Get the Model URI\n",
        "model_uri = json.loads(train_model_response.text)[\"self\"]\n",
        "print(\"Model URI:\", model_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "201\nModel URI: https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.1/models/ebadfd8d-8067-4896-8c7c-330793f6044f\n"
        }
      ],
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697554168590
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Deploy the model\n",
        "[Documentation for the API](https://eastus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-1/operations/Endpoints_Create)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the headers for the REST API calls\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# Define the request body for a new dataset\n",
        "deploy_model_request_body = {\n",
        "  \"project\": {\n",
        "    \"self\": f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/projects/{project_id}\"\n",
        "  },\n",
        "  \"properties\": {\n",
        "    \"loggingEnabled\": \"true\"\n",
        "  },\n",
        "  \"displayName\": \"airliftdemo\",\n",
        "  \"description\": \"Custom STT Model used in the Airlift demo\",\n",
        "  \"model\": {\n",
        "    \"self\": model_uri\n",
        "  },\n",
        "  \"locale\": locale,\n",
        "}\n",
        "\n",
        "# Build and call the URI\n",
        "deploy_model_uri = f\"https://{region}.api.cognitive.microsoft.com/speechtotext/v3.1/endpoints\"\n",
        "deploy_model_response = requests.post(url = deploy_model_uri, headers = headers, json = deploy_model_request_body)\n",
        "\n",
        "# 20* Represents a successful call \n",
        "print(deploy_model_response.status_code)\n",
        "\n",
        "# Get up the API endpoint URL (endpoint for short audios)\n",
        "endpoint_url = json.loads(deploy_model_response.text)[\"links\"][\"restInteractive\"]\n",
        "print(\"Endpoint URL:\", model_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "201\nEndpoint URL: https://westeurope.api.cognitive.microsoft.com/speechtotext/v3.1/models/ebadfd8d-8067-4896-8c7c-330793f6044f\n"
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697556924599
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Consuming the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pointers to the file\n",
        "example_path = \"dataset/PS4_XboxOne.wav\""
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697558676692
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the request headers\n",
        "headers = {\n",
        "    \"Ocp-Apim-Subscription-Key\": speech_key,\n",
        "    \"Content-Type\": \"audio/wav\"\n",
        "}\n",
        "\n",
        "# Read the audio file\n",
        "with open(example_path, \"rb\") as file:\n",
        "    audio_data = file.read()\n",
        "\n",
        "# Send the API request\n",
        "response = requests.post(endpoint_url, headers=headers, data=audio_data)\n",
        "\n",
        "# Get the response content as JSON\n",
        "json_response = json.loads(response.content)\n",
        "\n",
        "# Print the recognized text\n",
        "if \"DisplayText\" in json_response:\n",
        "    print(json_response[\"DisplayText\"])\n",
        "else:\n",
        "    print(\"Error: \" + json_response[\"RecognitionStatus\"])\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "First there was Play Station, AKA PS1, PS2, PS3 and now PS4. And that makes sense, You think after Xbox there'd be Xbox too. But no. Next came Xbox 360 and now after 360 comes Xbox One.\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1697558689693
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}